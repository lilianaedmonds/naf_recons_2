{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe967132",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "parent_folder = str(Path.cwd().parents[1])\n",
    "if parent_folder not in sys.path:\n",
    "    sys.path.append(parent_folder)\n",
    "\n",
    "from sigpy import mri\n",
    "import scipy\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import sigpy as sp\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from sigpy.mri.app import TotalVariationRecon, L1WaveletRecon\n",
    "from scipy.io import savemat\n",
    "import twixtools\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import medfilt\n",
    "from scipy.signal import butter,filtfilt\n",
    "\n",
    "\n",
    "## My files\n",
    "from ksp_plot_helpers import plot_ksp_data_multichannel, find_and_plot_acquired_region\n",
    "from raw_data_utils import get_kspace_data, get_TR\n",
    "from resp_signal_functions import resp_signal_all_slices, resp_signal_single_slice, resp_signal_center_sample_single_slice\n",
    "from resp_signal_plot_functions import *\n",
    "import gating_functions\n",
    "from pca_helper import pca_resp_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34967352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Software version: VD/VE (!?)\n",
      "\n",
      "Scan  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15.9G/15.9G [00:12<00:00, 1.32GB/s]\n"
     ]
    }
   ],
   "source": [
    "data_file_pt2 = '/data/lilianae/NaF_Patient2/anon_meas_MID00082_FID64646_Tho_fl3d_star_vibe_991_nav_tj_2000sp_AllCoils_SOS_2.dat'\n",
    "# data_file_pt1 = '/data/lilianae/NaF_MtSinai/anon_meas_MID00118_FID60738_Tho_fl3d_star_vibe_991_nav_tj_2000sp_AllCoils_SOS.dat'\n",
    "\n",
    "\n",
    "multi_twix = twixtools.read_twix(str(data_file_pt2))\n",
    "mapped = twixtools.map_twix(multi_twix)\n",
    "\n",
    "# # mapped[0] is sens data\n",
    "# data_0 = mapped[0]['image']\n",
    "# data_0.flags['remove_os']=True\n",
    "# echo_num=0                                                 # first echo is spoke data\n",
    "# num_points = int(mapped[0]['hdr']['Config']['NImageLins'])  # number of points on one spoke\n",
    "# num_full_par = int(mapped[0]['hdr']['Config']['NImagePar'])  # number of points on one spoke)\n",
    "# print(f'Full number of partitions = {num_full_par}')\n",
    "# print(f'Number of readouts = {num_points}')\n",
    "\n",
    "\n",
    "# ksp_data = data_0[...,echo_num,0,0,0,:,0,0,:,:,:]\n",
    "# ksp_data = ksp_data.squeeze()\n",
    "# # print(ksp_data.shape)\n",
    "# ksp_data = np.transpose(ksp_data,(2,0,1,3))\n",
    "# print(f'ksp_data.shape = {ksp_data.shape}')  ## Shape = (15, 58, 2002, 256) -> (channels, partitions, lines, columns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e938a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twixtools.recon_helpers import remove_oversampling\n",
    "chronological_data = []\n",
    "mdb_list = []\n",
    "\n",
    "for i, mdb in enumerate(multi_twix[-1]['mdb']):\n",
    "## Use same logic as twix_category['image'] to get mdh values for k-space\n",
    "    if (not mdb.is_flag_set('SYNCDATA') and\n",
    "        not mdb.is_flag_set('ACQEND') and\n",
    "        not mdb.is_flag_set('RTFEEDBACK') and\n",
    "        not mdb.is_flag_set('HPFEEDBACK') and\n",
    "        not mdb.is_flag_set('REFPHASESTABSCAN') and\n",
    "        not mdb.is_flag_set('PHASESTABSCAN') and\n",
    "        not mdb.is_flag_set('PHASCOR') and\n",
    "        not mdb.is_flag_set('NOISEADJSCAN') and\n",
    "        not mdb.is_flag_set('noname60') and\n",
    "        (not mdb.is_flag_set('PATREFSCAN') or mdb.is_flag_set('PATREFANDIMASCAN'))):\n",
    "\n",
    "        if not np.isnan(mdb.mdh.TimeStamp):\n",
    "            ## Extract k-space data for this readout\n",
    "            mdb_data = mdb.data  # Shape: (channels, samples)\n",
    "\n",
    "            ## Apply oversampling removal to ensure consistent array sizes\n",
    "            if mdb_data.shape[-1] == 512:  ## if we have 512 points, this is an image line. If there are 704 points, it is a noise scan. Discovered from manual inspection\n",
    "\n",
    "                # mdb_data, _ = remove_oversampling(mdb_data, x_was_in_timedomain=True)\n",
    "                mdb_data = mdb_data    ## Only take first 256 samples, same as logic Michael used in former data processing code\n",
    "                mdb_list.append(mdb)\n",
    "                \n",
    "                \n",
    "                chronological_data.append({\n",
    "                    'timestamp': mdb.mdh.TimeStamp,\n",
    "                    'partition': mdb.mdh.Counter.Par,\n",
    "                    'line': mdb.mdh.Counter.Lin,\n",
    "                    'kspace_data': mdb_data,  # Shape: (channels, 256)\n",
    "                    'ice_param' : mdb.mdh.IceProgramPara[2],\n",
    "                    'acquisition_index': i  # Original position in MDB list\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc1858f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_io.BufferedReader' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msave_data_helpers\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43msave_data_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmdb_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull_mdb_list_with_os.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/naf_clean/save_data_helpers.py:76\u001b[0m, in \u001b[0;36mwrite_pickle\u001b[0;34m(var, filename)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Write variable to pickle file with given filename'''\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 76\u001b[0m     \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuccessfully saved as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle '_io.BufferedReader' object"
     ]
    }
   ],
   "source": [
    "import save_data_helpers\n",
    "\n",
    "save_data_helpers.write_pickle(mdb_list, 'full_mdb_list_with_os.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f171f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(mdb_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a959f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mdb_list[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0be12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import save_data_helpers\n",
    "\n",
    "# save_data_helpers.write_pickle(mdb_list, 'mdb_list_with_os.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f809f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import save_data_helpers\n",
    "\n",
    "mdb_list = save_data_helpers.read_pickle('mdb_list_with_os.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7a277d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image data from list of mdbs and sort into 3d k-space (+ coil dim.)\n",
    "def import_kspace(image_mdbs):\n",
    "\n",
    "    n_line = 1 + max([mdb.cLin for mdb in image_mdbs])\n",
    "    n_part = 1 + max([mdb.cPar for mdb in image_mdbs])\n",
    "    n_channel, n_column = image_mdbs[0].data.shape\n",
    "\n",
    "    out = np.zeros([n_part, n_line, n_channel, n_column], dtype=np.complex64)\n",
    "    for mdb in image_mdbs:\n",
    "        # '+=' takes care of averaging, but careful in case of other counters (e.g. echoes)\n",
    "        out[mdb.cPar, mdb.cLin] += mdb.data\n",
    "\n",
    "    return out  # 4D numpy array [n_part, n_line, n_channel, n_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da1bb81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape = (58, 2002, 15, 512)\n"
     ]
    }
   ],
   "source": [
    "out = import_kspace(mdb_list)\n",
    "print(f'out.shape = {out.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f7fabd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved as ksp_from_mdb_512_samples.pkl\n"
     ]
    }
   ],
   "source": [
    "save_data_helpers.write_pickle(out, 'ksp_from_mdb_512_samples.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jointrecon_env_backup_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
